{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder implementation on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available and ready to use\n"
     ]
    }
   ],
   "source": [
    "# Checking for CUDA device \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"GPU available and ready to use\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using the CPU instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downloading the dataset\n",
    "\n",
    "datapath = \".\\data\\FasionMNIST\"  # Path of the downloaded (or to download) data\n",
    "\n",
    "# Check if data is already downloaded, if it is just load it, otherwise fetch it\n",
    "if os.path.isdir(datapath):\n",
    "    Train_dataset = FashionMNIST(root = datapath + \"\\Train\", download = False)\n",
    "    Test_dataset = FashionMNIST(root = datapath + \"\\Test\", train = False, download = False)\n",
    "else:\n",
    "    Train_dataset = FashionMNIST(root = datapath + \"\\Train\", download = True)\n",
    "    Test_dataset = FashionMNIST(root = datapath + \"\\Test\", train = False, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, the datapoints need to be transformed to tensors#\n",
    "Train = []\n",
    "Test = []\n",
    "for x, y in Train_dataset:\n",
    "    # flattening the images (with .reshape) so they're compatible with a FFNN (Feed forward neural network)\n",
    "    Train.append(torch.from_numpy(np.array(x).reshape(784)/256)) # Dividing by 256 to normalize the pixel values\n",
    "    \n",
    "for x, y in Test_dataset:\n",
    "    Test.append(torch.from_numpy(np.array(x).reshape(784)/256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b0cf46a3a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing one datapoint as an example\n",
    "plt.imshow(Train[200].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # The encoder part of the architecture\n",
    "        self.encoder = nn.Sequential(\n",
    "                            nn.Linear(784,300),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(300,150),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(150,25),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(25,8),\n",
    "                            nn.ReLU(),\n",
    "                        )\n",
    "        \n",
    "        # The decoder part of the architecture\n",
    "        self.decoder = nn.Sequential(\n",
    "                            nn.Linear(8,25),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(25,150),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(150,300),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(300,784),\n",
    "                            nn.ReLU(),\n",
    "                        )\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
